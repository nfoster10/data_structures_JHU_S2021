The prompt questions for this module are:

    
    	Aides the designer/user hats on the use of a data structure.
    
    	When assesing complexity, we measure amount of time to execute code. memory allocations/space. Space is less of a concern currently since it is more readily available.

    	no, an upper bund for a function does not apply in all cases. below a value beta, the assumptions of the label g(n) break down as the complexity is erratic near the origin. 

    	Upper bounds informs the worst possible efficiency while lower bounds informs the best possible efficency past a point Beta. In my work, we typically most concerned with understanding the worst case scenario to reduce latency. However, we also use many mult-threaded processes in which certain race conditions can adversely affect threads so it also is important to understand how fast another thread might run as well.
  
    	when working near the origin or in other words with a very small data set. 
  
    	The label g(n) is just a represnetation and not accurate below a value beta. This was in reference to understanding the working space/domain of 'n'. if you know that you are only working in a space of 'n' where f1 is better than f2. f1 should be used even if f2 is better for another range of 'n'

    	It is not as important since memory is an affordable resource. What is more important is the time it takes to process. Depending on the complexity, some algorithms can quickly take an absurdly long time to execute. 